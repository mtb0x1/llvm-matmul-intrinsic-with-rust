use std::env;
use std::path::PathBuf;
use std::process::Command;

#[cfg(feature = "gpu")]
fn getsmarch() -> String {
    let output = Command::new("nvidia-smi")
        .args(&["--query-gpu=compute_cap", "--format=csv,noheader"])
        .output()
        .expect("nvidia-smi failed");

    let cap_str = String::from_utf8_lossy(&output.stdout);
    let cap: Vec<&str> = cap_str.trim().split('.').collect();
    format!("{}{}", cap[0], cap[1]) //75
}

#[cfg(feature = "gpu")]
fn compile_llvm_ir_for_gpu(ll_file: &PathBuf, obj_file: &PathBuf) {
    println!("cargo:rerun-if-changed=src/llvm/{}", ll_file.display());
    let bc_file = obj_file.with_extension("bc");
    let ptx_file = obj_file.with_extension("ptx");

    //compile .ll to .bc
    let mut llvm_as_command = Command::new("llvm-as");
    llvm_as_command.arg(ll_file).arg("-o").arg(&bc_file);
    let status = llvm_as_command
        .status()
        .expect("Failed to execute llvm-as. Make sure LLVM llvm-as is installed and in PATH.");
    if !status.success() {
        panic!("llvm-as failed to compile LLVM IR file: {:?}", ll_file);
    }

    // compile .bc to .ptx
    // llc needs to have the capacity to target NVPTX (check llvm build flags)
    let mut llc_command = Command::new("llc");
    //eprintln!("=====> sm_arch is {}", getsmarch());
    llc_command
        .arg("-march=nvptx64")
        .arg(format!("-mcpu=sm_{}", getsmarch()))
        .arg("-o")
        .arg(&ptx_file)
        .arg(&bc_file);
    let status = llc_command
        .status()
        .expect("Failed to execute llc. Make sure LLVM llc is installed and in PATH.");
    if !status.success() {
        panic!("llc failed to compile LLVM IR for GPU, file: {:?}", ll_file);
    }

    // compile .ptx to .bin (fatcubin)
    // FIXME : --generate-code is not working, this is the way to force SASS (Streaming "mutliprocessor"? ASSembler)
    // the FATBIN contains SASS for the current GPU, it is loaded directly.
    // this is the most compiled form possible.
    // check https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html
    // for now we can check if the .fatbin have a SASS section.
    // cuobjdump --dump-sass "target/debug/build/llvm-intrinsic-with-rust-*/out/matmul_for_gpu.fatbin"
    let mut fatbin = Command::new("nvcc");
    fatbin
        //.arg(format!(
        //     "--generate-code arch={}{},code={}{}",
        //     "compute_",
        //     getsmarch(),
        //     "sm_",
        //     getsmarch()
        // ))
        .arg("--fatbin")
        .arg(&ptx_file)
        .arg("-o")
        .arg(&obj_file);
    eprintln!("nvcc command: {:?}", fatbin);
    let status = fatbin.status().expect("nvcc fatbin failed");
    if !status.success() {
        panic!("nvcc failed to generate fatbin for {:?}", ll_file);
    }
}
fn compile_llvm_ir_for_cpu(ll_file: &PathBuf, obj_file: &PathBuf, is_debug: bool) {
    println!("cargo:rerun-if-changed=src/llvm/{}", ll_file.display());

    // .ll needs to be lowered (vectorized ?) by opt
    // cause guess what, llc is a piece of junk !
    let lowered_ll_file = obj_file.with_extension("lowered.ll");
    let mut opt_command = Command::new("opt");
    opt_command
        .arg("-passes=lower-matrix-intrinsics")
        .arg("-S")
        .arg("-o")
        .arg(&lowered_ll_file)
        .arg(ll_file);
    if is_debug {
        opt_command.arg("--debug-entry-values");
        opt_command.arg("-print-after=lower-matrix-intrinsics");
    } else {
        opt_command.arg("--thinlto-bc");
    }

    let status = opt_command
        .status()
        .expect("Failed to execute opt. Make sure LLVM opt is installed and in PATH.");

    if !status.success() {
        panic!(
            "opt failed to lower matrix intrinsics in LLVM IR for CPU, file: {:?}",
            ll_file
        );
    }

    // fine, there, you have a IR that
    // even my grandma can execute.
    let mut llc_command = Command::new("llc");
    llc_command
        .arg("-mattr=+avx2,+fma")
        .arg("-mcpu=native")
        .arg("--relocation-model=pic")
        .arg("-filetype=obj")
        /* pass FP optimization flags (-fp-contract=fast and --enable-unsafe-fp-math) to llc.
        without clear instruction to break ieee754 rules for fp rounding, llvm cannot optimize the fmul + fadd generated by the intrinsic into an FMA.
           in simpler terms, without this, the generated code will be suboptimal, unrolled version will be 2x faster.
         https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation
         https://llvm.org/docs/LangRef.html#llvm-fma-intrinsic
         be aware of precision : irony is that you generally GAIN precision, not lose it even we are breaking ieee754 rules.
         */
        .arg("-fp-contract=fast")
        /* this param have effect only on manualy generated/unrolled IR,
            in other terms, it will not affect api call @llvm.matrix.column.major.load/store
            unrolled(4x4)	Row (row-major)	        5.933 ns	inherent row-major access pattern and thus the generated code is faster.
            unrolled(4x4)	Column (column-major)	16.393 ns	conflicts with the unrolled code with row-major access pattern.
        */
        .arg("--matrix-default-layout=row-major") // row-major
        .arg("-o")
        .arg(obj_file)
        .arg(&lowered_ll_file);
    if is_debug {
        llc_command.arg("--asm-verbose");
        llc_command.arg("--debug-entry-values");
        llc_command.arg("--debugger-tune=gdb");
        // TODO : switch all to row major
        //llc_command.arg("--matrix-default-layout=row-major"); // row-major

        //llc_command.arg("-print-asm-code");
        //llc_command.arg("-time-passes");
    } else {
        llc_command.arg("-O3");
    }

    let status = llc_command
        .status()
        .expect("Failed to execute llc. Make sure LLVM llc is installed and in PATH.");

    if !status.success() {
        panic!("llc failed to compile LLVM IR for CPU, file: {:?}", ll_file);
    }
}

fn main() {
    let out_dir = PathBuf::from(env::var("OUT_DIR").unwrap());
    let manifest_dir = PathBuf::from(env::var("CARGO_MANIFEST_DIR").unwrap());

    let is_debug = env::var("PROFILE").unwrap_or_else(|_| "debug".to_string()) == "debug";

    // matmul_4x4.ll file contains :
    // - the llvm ir for the matmul with transpose operation
    // - the llvm ir for the matmul with unrolled operation

    // the transpose one need lowering with opt
    // LLVM matrix intrinsics (like llvm.matrix.transpose, llvm.matrix.multiply, llvm.matrix.column.major.load/store)
    // require lowering (i.e., transformation from high-level matrix intrinsic IR to something the backend
    // can actually JIT/compile))

    // the unrolled one I don't think it needs lowering
    // FIXME: move unrolled one to a different file
    // and avoid opting it (later for benchmark might have an impact)

    let matmul_4x4_ll = manifest_dir.join("src/llvm/matmul_4x4.ll");
    let matmul_4x4_obj = out_dir.join("matmul_4x4.o");
    compile_llvm_ir_for_cpu(&matmul_4x4_ll, &matmul_4x4_obj, is_debug);

    // link with all .o files
    println!("cargo:rustc-link-arg={}", matmul_4x4_obj.display());

    #[cfg(feature = "gpu")]
    {
        let matmul_file = manifest_dir.join("src/llvm/gpu/matmul_for_gpu.ll");
        let matmul_fatbin = out_dir.join("matmul_for_gpu.fatbin");
        compile_llvm_ir_for_gpu(&matmul_file, &matmul_fatbin);
        // Link against CUDA Driver API (libcuda.so)
        // Check common CUDA installation paths
        let common_cuda_lib_paths = vec![
            //"/usr/local/cuda/lib64",
            //"/usr/lib/x86_64-linux-gnu",
            //"/usr/lib64",
            //"/opt/cuda/lib64",
            "",
        ];

        for path in common_cuda_lib_paths {
            if std::path::Path::new(path).exists() {
                println!("cargo:rustc-link-search=native={}", path);
            }
        }

        // Also check CUDA_PATH environment variable if set
        if let Ok(cuda_path) = env::var("CUDA_PATH") {
            for path in [
                format!("{}", cuda_path),
                format!("{}/lib64", cuda_path),
                format!("{}/lib", cuda_path),
            ] {
                if std::path::Path::new(&path).exists() {
                    println!("cargo:rustc-link-search=native={}", path);
                }
            }
        }

        // link with all .o files
        //println!("cargo:rustc-link-arg={}", matmul_fatbin.display());

        // Tell cargo to link against libcuda
        println!("cargo:rustc-link-lib=dylib=cuda");
    }
}
